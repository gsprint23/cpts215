{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CptS 215 Data Analytics Systems and Algorithms](https://github.com/gsprint23/cpts215)\n",
    "[Washington State University](https://wsu.edu)\n",
    "\n",
    "[Gina Sprint](http://eecs.wsu.edu/~gsprint/)\n",
    "# Algorithm Analysis\n",
    "\n",
    "Learner objectives for this lesson\n",
    "* Understand time and space complexity\n",
    "* Discuss why it important to analyze algorithms for efficiency\n",
    "* Introduce Big O notation\n",
    "\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* [Miller and Ranum](http://interactivepython.org/runestone/static/pythonds/index.html)\n",
    "\n",
    "## Algorithm Analysis Overview\n",
    "We are now at the point in our computer science education where it is not enough to simply solve a problem. While it is still important that our solutions are correct, we want to ensure our solutions are *efficient*. We measure the efficiency of algorithms by the amount of work the algorithm does. How can we measure how much work an algorithm performs? The work done is typically related to the the data you are operating on. The data matters! Think about a sorting a list. If this list is already sorted, your algorithm may perform less work than if the list is unsorted.\n",
    "\n",
    "We have two fundamental concerns in terms of efficiency for a given algorithm:\n",
    "1. The time it takes to run, called *time complexity*\n",
    "1. The space it takes to run, called *space complexity*\n",
    "\n",
    "We will mostly focus on time complexity, since it will give us a general idea of how an algorithm will perform.\n",
    "\n",
    "## Time Complexity\n",
    "Time complexity  let's us compare two solutions to the same problem, and decide which solution to use because it is \"faster\", i.e. it has better time complexity. \n",
    "\n",
    "To determine an algorithm's time complexity, we can count the number of times each operation in an algorithm occurs. This count is often called the growth rate function, $T(n)$, where $n$ is the \"size of the problem\". Recall, the count of data items an algorithm operates on is typically referred to by the letter `n`, e.g. the length of a list is `n` items. We can express an algorithm's operation count, $T$, in terms of $n$. \n",
    "\n",
    "### Example 1\n",
    "Let's take a look at an example:\n",
    "\n",
    "```python\n",
    "def print_list(alist):\n",
    "    i = 0\n",
    "    while i < len(alist):\n",
    "        print(alist[i])\n",
    "        i += 1\n",
    "```\n",
    "\n",
    "The operations in `print_list()` include:\n",
    "* 1 assignment (`i = 0`)\n",
    "* `n + 1` comparisons (`i < len(alist)`)\n",
    "* `n` calls to `print()`\n",
    "* `n` addition/assignment combos (`i += 1`)\n",
    "\n",
    "$T(n) = 1 + n + (n + 1) + n = 3n + 2$\n",
    "\n",
    "## Big O Notation\n",
    "Now, to get the algorithm's time complexity, we take the dominant term in $T(n)$ and throw away the remaining terms. The dominant term is called the \"order\" of the algorithm and is represented by a big letter O (short for order). Big O notation is used to denote time complexity. Thus, the time complexity of the previous example algorithm is $\\mathcal{O}(n)$. As $n$ gets large, the constant 2 is insignificant in terms of the efficiency of the algorithm.\n",
    "\n",
    "Let's take a look at common time complexities:\n",
    "\n",
    "|Relative speed|Big O|Name|Example|\n",
    "|---------------|-----|----|-------|\n",
    "|Fastest|$\\mathcal{O}(1)$|Constant|Linked list insert at front|\n",
    "||$\\mathcal{O}(\\log_{2} n)$|Logarithmic|Binary search|\n",
    "||$\\mathcal{O}(n)$|Linear|Linear search|\n",
    "||$\\mathcal{O}(n \\log_{2} n)$|Log linear|Merge sort, quick sort|\n",
    "||$\\mathcal{O}(n^{2})$|Quadratic|Bubble sort, selection sort, insertion sort|\n",
    "||$\\mathcal{O}(n^{3})$|Cubic|Matrix multiplication|\n",
    "|Slowest|$\\mathcal{O}(2^{n})$, $\\mathcal{O}(n!)$, $\\mathcal{O}(n^{n})$|Exponential|Towers of Hanoi, recursive Fibonacci|\n",
    "\n",
    "<img src=\"http://interactivepython.org/runestone/static/cpts215wsu/_images/newplot.png\" width=500>\n",
    "(image from [http://interactivepython.org/runestone/static/cpts215wsu/_images/newplot.png](http://interactivepython.org/runestone/static/cpts215wsu/_images/newplot.png))\n",
    "\n",
    "Polynomial time algorithms (i.e non-exponential) are much faster than exponential time algorithms! Note: This is the foundation for the [P vs NP (non-polynomial) problem](https://en.wikipedia.org/wiki/P_versus_NP_problem).\n",
    "\n",
    "In general, we strive for constant time complexity (same amount of time/work regardless of data set size)! For many problems, this is impossible to achieve (e.g. sorting!). So we aim for the best efficiency we can for our data set.\n",
    "\n",
    "### Example 2\n",
    "Let's take a look at another Big O example. Suppose we want to sum the items in a `n`x`n` 2-dimensional list:\n",
    "\n",
    "```python\n",
    "def sum_2d_list(alist):\n",
    "    summ = 0\n",
    "    i = 0\n",
    "    while i < len(alist):\n",
    "        j = 0\n",
    "        while j < len(alist[i]):\n",
    "            summ += alist[i][j]\n",
    "            j += 1\n",
    "        i += 1\n",
    "    return summ\n",
    "```\n",
    "\n",
    "The operations in `sum_list()` include:\n",
    "* 2 assignments (`summ = 0` and `i = 0`)\n",
    "* Outer loop:\n",
    "    * `n + 1` comparisons (`i < len(alist)`)\n",
    "    * `n` assignments (`j = 0`)\n",
    "    * `n` addition/assignment combos (`i += 1`)\n",
    "* Inner loop:\n",
    "    * `n * (n + 1)` comparisons (`j < len(alist[i])`)\n",
    "    * `n * n` addition/assignment combos (`j += 1`)\n",
    "    * `n * n` addition/assignment combos (`summ += alist[i][j]`)\n",
    "\n",
    "$T(n) = 2 + (n + 1) + n + n + n(n + 1) + n^{2} + n^{2} = 3n^{2} + 4n + 3 \\rightarrow \\mathcal{O}(n^{2})$\n",
    "\n",
    "### Example 3\n",
    "What is the time complexity for linear search?\n",
    "\n",
    "```python\n",
    "def linear_search(alist, target):\n",
    "    for i in range(len(alist)):\n",
    "        if alist[i] == target:\n",
    "            return i\n",
    "    return -1\n",
    "```\n",
    "\n",
    "The operations in `linear_search()` include:\n",
    "* `n` comparisons (`alist[i] == target`)\n",
    "\n",
    "$T(n) = n \\rightarrow \\mathcal{O}(n)$\n",
    "\n",
    "But what about the best case scenario, that is if `target` is the first item in `alist`? Then linear search has constant time complexity! We can further breakdown time complexity into best case, worst case, and average case.\n",
    "\n",
    "### Cases\n",
    "#### Best Case Performance\n",
    "The best case performance for an algorithm describes the algorithm's behavior under optimal conditions. For linear search, the best case scenario is if the item to find is the first item in the list, yielding best case performance of $\\mathcal{O}(1)$.\n",
    "\n",
    "Best case performance represents a *lower bound* on the performance of an algorithm. The special notation, $\\Omega$ (omega), is used to represent the time complexity for best case performance (e.g. for linear search, $\\Omega(1)$).\n",
    "\n",
    "#### Worst Case Performance\n",
    "The worst case performance for an algorithm describes the algorithm's behavior under the worst possible conditions. For linear search, the worst case scenario is if the item to find is the last item in the list or not in the list, yielding worst case performance of $\\mathcal{O}(n)$ (this is our big O representation for linear search).\n",
    "\n",
    "Worst case performance represents an *upper bound* on the performance of an algorithm.\n",
    "\n",
    "Note: When $\\mathcal{O} = \\Omega$, $\\Theta$ (theta), is used to denote the *tight bound* of the algorithm. That is, the algorithm's lower bound and upper bound are the same.\n",
    "\n",
    "#### Average Case Performance\n",
    "The average case performance for an algorithm describes the algorithm's behavior under \"average input\" conditions. In this case, we won't go into detail about average case performance because it can be difficult to characterize average input; however, for linear search, the average case scenario is $\\mathcal{O}(n)$, because each item is equally likely to be the target, so the algorithm will check $n/2$ items on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Problems\n",
    "### 1\n",
    "1. For the following code, label each operation with how many times the operation occurs.\n",
    "1. The growth rate function for the following code.\n",
    "    * Answer: $3n^{2} + 1$\n",
    "1. What will the array look like after the code finishes executing?\n",
    "    * Answer: Each element in the array will contain the original a_list[1], except the last element, which will contain a_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function(a_list):\n",
    "    for i in range(1, len(a_list), 1):\n",
    "        next_item = a_list[i]\n",
    "        shifter = len(a_list) - 1\n",
    "        \n",
    "        while shifter > 0:\n",
    "            a_list[shifter] = a_list[shifter - 1]\n",
    "            shifter -= 1\n",
    "        a_list[shifter] = next_item\n",
    "        \n",
    "chars = list(\"abcdefghijklmnop\")\n",
    "#print(chars)\n",
    "my_function(chars)\n",
    "#print(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "What is $\\mathcal{O}(n)$ for the following code snippets? Justify your answer with a growth rate function or with a description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 2.a.\n",
    "def func1(n):\n",
    "    if n > 0:\n",
    "        print(\"n: \" + n)\n",
    "        func1(n - 1)\n",
    "        func1(n - 1)\n",
    "    elif n < 0:\n",
    "        func1(n + 1)\n",
    "        func1(n + 1)\n",
    "        print(\"n: \" + n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.a. Answer: $\\mathcal{O}(n) = 2^{n}$\n",
    "\n",
    "For every one call of `func1()`, you get two additional calls of `func1()`. It is exponential recursion. If `n` is 0, the function will run $\\mathcal{O}(1)$ since both `if` and `elif` statements will evaluate to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.b.\n",
    "def func2(n):\n",
    "    i = n // 2\n",
    "    while i > 0:\n",
    "        for j in range(0, n, 1):\n",
    "            for k in range(0, n, 1):\n",
    "                print(\"i: %d j: %d k: %d\" %(i, j, k))\n",
    "        i //= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.b. Answer: $\\mathcal{O}(n) = n^{2}log_{2}(n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.c. (tricky!)\n",
    "i = n\n",
    "while i > 0:\n",
    "    j = 1\n",
    "    while j < n:\n",
    "        k = 1\n",
    "        while k < 2 ** n:\n",
    "            print(\"i: %s j: %d k: %d\" %(i, j, k))\n",
    "            k *= 2\n",
    "        j *= 2\n",
    "    i //= 2   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.c. Answer: $\\mathcal{O}(n (log_{n})^{2})$"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
