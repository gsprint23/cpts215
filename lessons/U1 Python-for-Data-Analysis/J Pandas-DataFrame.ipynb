{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CptS 215 Data Analytics Systems and Algorithms](https://github.com/gsprint23/cpts215)\n",
    "[Washington State University](https://wsu.edu)\n",
    "\n",
    "[Gina Sprint](http://eecs.wsu.edu/~gsprint/)\n",
    "# Pandas `DataFrame`\n",
    "\n",
    "Learner objectives for this lesson:\n",
    "* Learn about the `pandas` library\n",
    "* Work with `Series`, `DataFrame`, and `Panel` objects\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* [Pandas website](http://pandas.pydata.org/)\n",
    "* Python for Data Analysis by Wes McKinney"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DataFrame`\n",
    "`DataFrame` is a two dimensional labeled data structure. `DataFrame` has index (just like `Series`). Each `DataFrame` index value *maps* to a labeled `Series`. You can think of a `DataFrame` like an Excel spreadsheet, SQL table, or a dict of `Series` objects. The index represents the rows and the `Series` represents the columns. \n",
    "\n",
    "Like Series, DataFrame accepts many different kinds of input:\n",
    "* Dictionary of 1D array-like objects (`ndarrays`, lists, dictionaries, or `Series`)\n",
    "* 2-D `ndarray`\n",
    "* Structured or record `ndarray`\n",
    "* A `Series`\n",
    "* Another `DataFrame`\n",
    "\n",
    "### `DataFrame` from Lists\n",
    "Let's expand our Washington city population `Series` example. Suppose we want to store the four most populated cities in Washington, Idaho, and Oregon. Let's declare dictionaries to store this new information. Then we will create a `DataFrame` to represent all three states' populations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0        1         2            3\n",
      "0   Seattle  Spokane    Tacoma    Vancouver\n",
      "1     Boise    Nampa  Meridian  Idaho Falls\n",
      "2  Portland   Eugene     Salem      Gresham\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "washington = [\"Seattle\", \"Spokane\", \"Tacoma\", \"Vancouver\"]\n",
    "idaho = [\"Boise\", \"Nampa\", \"Meridian\", \"Idaho Falls\"]\n",
    "oregon = [\"Portland\", \"Eugene\", \"Salem\", \"Gresham\"]\n",
    "pops = [washington, idaho, oregon]\n",
    "df = pd.DataFrame(pops)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas stacks the nested list into a 2-dimensional `DataFrame`. By default, the index and columns are labeled as 0-based indices. Instead, we want to provide labels to help with indexing later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population DataFrame #1\n",
      "           1        2         3            4\n",
      "WA   Seattle  Spokane    Tacoma    Vancouver\n",
      "ID     Boise    Nampa  Meridian  Idaho Falls\n",
      "OR  Portland   Eugene     Salem      Gresham\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = pd.DataFrame(pops, index=[\"WA\", \"ID\", \"OR\"], columns=np.arange(1, len(washington) + 1))\n",
    "print(\"Population DataFrame #1\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame` from Dictionaries\n",
    "Let's re-work the above example to build the `DataFrame` from dictionaries. This can be useful because the dictionary keys will be used for the `DataFrame` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID        OR         WA\n",
      "0        Boise  Portland    Seattle\n",
      "1        Nampa    Eugene    Spokane\n",
      "2     Meridian     Salem     Tacoma\n",
      "3  Idaho Falls   Gresham  Vancouver\n"
     ]
    }
   ],
   "source": [
    "pops_dict = {\"WA\": washington, \"ID\": idaho, \"OR\": oregon}\n",
    "df2 = pd.DataFrame(pops_dict)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then update the index to start at 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population DataFrame #2\n",
      "            ID        OR         WA\n",
      "1        Boise  Portland    Seattle\n",
      "2        Nampa    Eugene    Spokane\n",
      "3     Meridian     Salem     Tacoma\n",
      "4  Idaho Falls   Gresham  Vancouver\n"
     ]
    }
   ],
   "source": [
    "df2.index += 1\n",
    "print(\"Population DataFrame #2\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `df` (Population `DataFrame` #1) and `df2` (Population `DataFrame` #2) are the transpose of each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1        2         3            4\n",
      "ID     Boise    Nampa  Meridian  Idaho Falls\n",
      "OR  Portland   Eugene     Salem      Gresham\n",
      "WA   Seattle  Spokane    Tacoma    Vancouver\n",
      "           1        2         3            4\n",
      "ID     Boise    Nampa  Meridian  Idaho Falls\n",
      "OR  Portland   Eugene     Salem      Gresham\n",
      "WA   Seattle  Spokane    Tacoma    Vancouver\n",
      "       1     2     3     4\n",
      "ID  True  True  True  True\n",
      "OR  True  True  True  True\n",
      "WA  True  True  True  True\n"
     ]
    }
   ],
   "source": [
    "df2T = df2.T # transpose\n",
    "# re-order\n",
    "df = df.sort_index()\n",
    "df2T = df2T.sort_index()\n",
    "print(df)\n",
    "print(df2T)\n",
    "print(df == df2T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if the dictionaries used to create a `DataFrame` do not have the same keys? Just like with `Series`, the `DataFrame` index of unaligned columns will be the union of the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ID        OR        WA\n",
      "Bellevue            NaN       NaN  133992.0\n",
      "Boise          205671.0       NaN       NaN\n",
      "Coeur d'Alene   44137.0       NaN       NaN\n",
      "Corvallis           NaN   54462.0       NaN\n",
      "Eugene              NaN  156185.0       NaN\n",
      "Hillsboro           NaN   91611.0       NaN\n",
      "Leavenworth         NaN       NaN    1992.0\n",
      "Moscow          23800.0       NaN       NaN\n",
      "Nampa           81557.0       NaN       NaN\n",
      "Portland            NaN  583776.0       NaN\n",
      "Seattle             NaN       NaN  652405.0\n",
      "Spokane             NaN       NaN  210721.0\n"
     ]
    }
   ],
   "source": [
    "washington = {\"Seattle\": 652405, \"Spokane\": 210721, \"Bellevue\": 133992, \"Leavenworth\": 1992}\n",
    "idaho = {\"Boise\": 205671, \"Nampa\": 81557, \"Coeur d'Alene\": 44137, \"Moscow\": 23800}\n",
    "oregon = {\"Portland\": 583776, \"Eugene\": 156185, \"Hillsboro\": 91611, \"Corvallis\": 54462}\n",
    "pops = {\"WA\": washington, \"ID\": idaho, \"OR\": oregon}\n",
    "df = pd.DataFrame(pops)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataFrame` from `ndarray`\n",
    "As another example, let's create a `DataFrame` from random data stored in an `ndarray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3      col4\n",
      "a  1.108062  0.670847  1.108137 -0.250980\n",
      "b  0.183961 -1.714299 -0.739520 -0.319820\n",
      "c  1.286052 -0.927832  1.650807  0.895659\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import randn\n",
    "rand_data = randn(3, 4)\n",
    "rand_df = pd.DataFrame(rand_data, index=[\"a\", \"b\", \"c\"], columns=[\"col1\", \"col2\", \"col3\", \"col4\"])\n",
    "print(rand_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Columns\n",
    "You can treat a `DataFrame` semantically like a dictionary of like-indexed `Series` objects. Getting, setting, and deleting columns works with the same syntax as the analogous dictionary operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3      col4\n",
      "a -0.013056 -0.718166  1.628721  1.705919\n",
      "b -0.449616  0.158878  0.592754  0.000759\n",
      "c  0.151376  0.967503 -0.941538 -0.499192\n",
      "a   -0.718166\n",
      "b    0.158878\n",
      "c    0.967503\n",
      "Name: col2, dtype: float64\n",
      "       col1      col2      col3  col4\n",
      "a -0.013056 -0.718166  1.628721   100\n",
      "b -0.449616  0.158878  0.592754   100\n",
      "c  0.151376  0.967503 -0.941538   100\n",
      "       col1      col2      col3  col4   col5\n",
      "a -0.013056 -0.718166  1.628721   100   True\n",
      "b -0.449616  0.158878  0.592754   100  False\n",
      "c  0.151376  0.967503 -0.941538   100  False\n",
      "       col1      col2      col3  col4   col5         sum\n",
      "a -0.013056 -0.718166  1.628721   100   True  101.897499\n",
      "b -0.449616  0.158878  0.592754   100  False  100.302016\n",
      "c  0.151376  0.967503 -0.941538   100  False  100.177341\n",
      "       col1      col2  ones      col3  col4   col5         sum\n",
      "a -0.013056 -0.718166     1  1.628721   100   True  101.897499\n",
      "b -0.449616  0.158878     1  0.592754   100  False  100.302016\n",
      "c  0.151376  0.967503     1 -0.941538   100  False  100.177341\n",
      "       col1      col2  ones      col3  col4         sum\n",
      "a -0.013056 -0.718166     1  1.628721   100  101.897499\n",
      "b -0.449616  0.158878     1  0.592754   100  100.302016\n",
      "c  0.151376  0.967503     1 -0.941538   100  100.177341\n",
      "       col1      col2  ones      col3  col4\n",
      "a -0.013056 -0.718166     1  1.628721   100\n",
      "b -0.449616  0.158878     1  0.592754   100\n",
      "c  0.151376  0.967503     1 -0.941538   100\n",
      "Popped column is a Series:\n",
      "a    101.897499\n",
      "b    100.302016\n",
      "c    100.177341\n",
      "Name: sum, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "rand_data = randn(3, 4)\n",
    "rand_df = pd.DataFrame(rand_data, index=[\"a\", \"b\", \"c\"], columns=[\"col1\", \"col2\", \"col3\", \"col4\"])\n",
    "print(rand_df)\n",
    "\n",
    "# index column\n",
    "print(rand_df[\"col2\"])\n",
    "# update column\n",
    "rand_df[\"col4\"] = 100 # 100 is propogated to fill the column\n",
    "print(rand_df)\n",
    "# add columns (inserted at end)\n",
    "rand_df[\"col5\"] = rand_df[\"col1\"] > rand_df[\"col2\"]\n",
    "print(rand_df)\n",
    "rand_df[\"sum\"] = rand_df.sum(axis=\"columns\")\n",
    "print(rand_df)\n",
    "# add columns at location\n",
    "rand_df.insert(2, \"ones\", 1)\n",
    "print(rand_df)\n",
    "# delete columns\n",
    "del rand_df[\"col5\"]\n",
    "print(rand_df)\n",
    "sum_ser = rand_df.pop(\"sum\")\n",
    "print(rand_df)\n",
    "print(\"Popped column is a Series:\")\n",
    "print(sum_ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "From the [Pandas website](http://pandas.pydata.org/), the basics of indexing are as follows:\n",
    "\n",
    "|Operation|Syntax|Result|\n",
    "|-|-|-|\n",
    "|Select column\t|`df[col]`\t|`Series`|\n",
    "|Select row by label\t|`df.loc[label]`|\t`Series`|\n",
    "|Select row by integer location\t|`df.iloc[loc]`\t|`Series`|\n",
    "|Slice rows\t|`df[5:10]`\t|`DataFrame`|\n",
    "|Select rows by boolean vector\t|`df[bool_vec]`|\t`DataFrame`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col1      col2      col3      col4\n",
      "a  0.084633  0.604611  0.666690  0.043860\n",
      "b -1.742362  1.355383  1.167826  0.491943\n",
      "c  0.746066 -1.503622 -0.663647 -0.463522\n",
      "col1   -1.742362\n",
      "col2    1.355383\n",
      "col3    1.167826\n",
      "col4    0.491943\n",
      "Name: b, dtype: float64\n",
      "col1   -1.742362\n",
      "col2    1.355383\n",
      "col3    1.167826\n",
      "col4    0.491943\n",
      "Name: b, dtype: float64\n",
      "       col1      col2      col3      col4\n",
      "a  0.084633  0.604611  0.666690  0.043860\n",
      "b -1.742362  1.355383  1.167826  0.491943\n"
     ]
    }
   ],
   "source": [
    "rand_data = randn(3, 4)\n",
    "rand_df = pd.DataFrame(rand_data, index=[\"a\", \"b\", \"c\"], columns=[\"col1\", \"col2\", \"col3\", \"col4\"])\n",
    "print(rand_df)\n",
    "\n",
    "# row indexing by label\n",
    "print(rand_df.loc[\"b\"])\n",
    "# row indexing by location\n",
    "print(rand_df.iloc[1])\n",
    "# row slicing by location\n",
    "print(rand_df[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining `DataFrame`s\n",
    "Pandas supports many ways to combine `DataFrame`s together, including merging, joining, and concatenating. For simplicity, we will focus on concatenation with the `concat` function in the main Pandas namespace. \n",
    "\n",
    "Suppose we have three `DataFrame`s with the same column labels that we want to combine into a single `DataFrame`. We can use `pd.concat(<list of DataFrames>)` to combine them. The following example is from the Pandas documentation on [merging](http://pandas.pydata.org/pandas-docs/stable/merging.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "10  A10  B10  C10  D10\n",
      "11  A11  B11  C11  D11\n",
      "Help on method tail in module pandas.core.generic:\n",
      "\n",
      "tail(n=5) method of pandas.core.frame.DataFrame instance\n",
      "    Returns last n rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "index=[0, 1, 2, 3])\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "index=[4, 5, 6, 7])\n",
    "\n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "index=[8, 9, 10, 11])\n",
    "\n",
    "frames = [df1, df2, df3]\n",
    "result = pd.concat(frames)\n",
    "print(result.tail(2))\n",
    "print(help(result.tail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `DataFrame` is a combination is `df3` concatenated to the end of `df2`, which is concatenated to the end of `df1`:\n",
    "![](http://pandas.pydata.org/pandas-docs/stable/_images/merging_concat_basic.png)\n",
    "(image from [http://pandas.pydata.org/pandas-docs/stable/_images/merging_concat_basic.png](http://pandas.pydata.org/pandas-docs/stable/_images/merging_concat_basic.png))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Large `DataFrame`s\n",
    "In this class we will be working with some big `DataFrame`s. Pandas will output condensed `DataFrame`s using .... There are also object methods to view shortened or summarized `DataFrame` information:\n",
    "* `describe()`: Generate various summary statistics, excluding NaN values\n",
    "* `head(n=5)`: Returns first `n` rows \n",
    "* `tail(n=5)`: Returns the last `n` rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         A   B   C   D\n",
      "count   12  12  12  12\n",
      "unique  12  12  12  12\n",
      "top     A8  B2  C5  D7\n",
      "freq     1   1   1   1\n",
      "\n",
      "\n",
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "\n",
      "\n",
      "      A    B    C    D\n",
      "10  A10  B10  C10  D10\n",
      "11  A11  B11  C11  D11\n"
     ]
    }
   ],
   "source": [
    "print(result.describe())\n",
    "print(\"\\n\")\n",
    "print(result.head(n=2))\n",
    "print(\"\\n\")\n",
    "print(result.tail(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File I/O\n",
    "With Pandas, we can easily write our data frames out to a csv (comma separated value) file to save for later use after our program terminates. The `DataFrame` method [`to_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html) write a data frame to a csv file. The rows and columns of the data frame will be the rows and columns of the csv file. \n",
    "\n",
    "For example, suppose we want to write to a file our example data frame we used to learn how to concatenate data frames together. We can do this in a one-liner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = r\"files\\results_df.csv\"\n",
    "result.to_csv(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we open results_df.csv with Microsoft Excel, we see the following table:\n",
    "<img src=\"https://raw.githubusercontent.com/gsprint23/cpts215/master/lessons/figures/results_df.png\" width=\"400\">\n",
    "\n",
    "We can also load data from a csv file into a data frame. To do this, we use the [`read_csv()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) Pandas function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0    A    B    C    D\n",
      "0            0   A0   B0   C0   D0\n",
      "1            1   A1   B1   C1   D1\n",
      "2            2   A2   B2   C2   D2\n",
      "3            3   A3   B3   C3   D3\n",
      "4            4   A4   B4   C4   D4\n",
      "5            5   A5   B5   C5   D5\n",
      "6            6   A6   B6   C6   D6\n",
      "7            7   A7   B7   C7   D7\n",
      "8            8   A8   B8   C8   D8\n",
      "9            9   A9   B9   C9   D9\n",
      "10          10  A10  B10  C10  D10\n",
      "11          11  A11  B11  C11  D11\n",
      "Index(['Unnamed: 0', 'A', 'B', 'C', 'D'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(fname)\n",
    "print(df)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we seem some less than desirable output. For example, the first column in the csv file is our index, but our data frame is creating and assigning a new index. We also have the extra column \"Unnamed: 0\". We can explicitly tell Pandas the first column is the index with the keyword `index_col`. It is also good to explicitly tell Pandas the first row is our header row and contains the column labels. We can do this with the keyword `header`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "0    A0   B0   C0   D0\n",
      "1    A1   B1   C1   D1\n",
      "2    A2   B2   C2   D2\n",
      "3    A3   B3   C3   D3\n",
      "4    A4   B4   C4   D4\n",
      "5    A5   B5   C5   D5\n",
      "6    A6   B6   C6   D6\n",
      "7    A7   B7   C7   D7\n",
      "8    A8   B8   C8   D8\n",
      "9    A9   B9   C9   D9\n",
      "10  A10  B10  C10  D10\n",
      "11  A11  B11  C11  D11\n",
      "Index(['A', 'B', 'C', 'D'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# another attempt at reading in the csv data\n",
    "df = pd.read_csv(fname, index_col=0, header=0)\n",
    "print(df)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Panel`\n",
    "From the [Pandas website](http://pandas.pydata.org/):\n",
    ">Panel is a somewhat less-used, but still important container for 3-dimensional data. The term panel data is derived from econometrics and is partially responsible for the name pandas: pan(el)-da(ta)-s. The names for the 3 axes are intended to give some semantic meaning to describing operations involving panel data and, in particular, econometric analysis of panel data. However, for the strict purposes of slicing and dicing a collection of DataFrame objects, you may find the axis names slightly arbitrary:\n",
    "* items: axis 0, each item corresponds to a DataFrame contained inside\n",
    "* major_axis: axis 1, it is the index (rows) of each of the DataFrames\n",
    "* minor_axis: axis 2, it is the columns of each of the DataFrames\n",
    "\n",
    "We will not officially cover `Panel`s at this point in the course. You are welcome to read up on them if you would like.\n",
    "\n",
    "## Summary\n",
    "We have covered quite a bit of information on Pandas, but we have only scratched the surface! I highly encourage you to read *Python for Data Analysis* by Wes McKinney and practice working with `Series` and `DataFrame` objects. Over the course of the semester we will learn new Pandas functionality as we go. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
